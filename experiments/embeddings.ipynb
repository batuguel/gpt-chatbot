{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering using Embeddings\n",
    "\n",
    "In this notebook, a different approach is tested to get GPT to answer questions about data outside its training data.\n",
    "Following the official documentation and the tutorial on: https://cookbook.openai.com/examples/question_answering_using_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "import os # for getting API token from env variable OPENAI_API_KEY\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "from dotenv import load_dotenv\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Select models and initialize client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # the model to use for embeddings\n",
    "GPT_MODEL = 'gpt-3.5-turbo'  # the model to use for text generation\n",
    "\n",
    "# Load OpenAI API key\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# initialize client\n",
    "client = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate embedding for sushi JSON\n",
    "\n",
    "For this trial, we use embeddings for each element in the JSON file. For sushi.json this means each restaurant entry is embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sushi data\n",
    "with open('../chatbot-backend/sushi.json', 'r') as file:\n",
    "    sushi_data = json.load(file)\n",
    "\n",
    "def generate_embeddings_from_sushi_json(sushi_data: list) -> pd.DataFrame:\n",
    "    embeddings = []\n",
    "    for restaurant in sushi_data:\n",
    "        # Convert the restaurant data to a JSON string\n",
    "        # We could also create descriptive texts, but this is easier for now\n",
    "        json_str = json.dumps(restaurant)\n",
    "        \n",
    "        # Generate embedding for the JSON string\n",
    "        embedding = client.embeddings.create(input = json_str, model=EMBEDDING_MODEL).data[0].embedding\n",
    "        \n",
    "        # Append the embedding and associated restaurant title to the list\n",
    "        embeddings.append({'Restaurant': restaurant['title'], 'Embedding': embedding})\n",
    "    \n",
    "    return pd.DataFrame(embeddings)\n",
    "\n",
    "df_embeddings_sushi = generate_embeddings_from_sushi_json(sushi_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sasou</td>\n",
       "      <td>[0.007590070366859436, 0.02465105429291725, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Galeria Restaurant</td>\n",
       "      <td>[0.0037229920271784067, 0.01896066591143608, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shaokao Asian Grill&amp;Wine</td>\n",
       "      <td>[0.022152040153741837, 0.01048024371266365, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Secret Garden</td>\n",
       "      <td>[0.01569896563887596, 0.009590079076588154, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Restaurant                                          Embedding\n",
       "0                     Sasou  [0.007590070366859436, 0.02465105429291725, -0...\n",
       "1        Galeria Restaurant  [0.0037229920271784067, 0.01896066591143608, -...\n",
       "2  Shaokao Asian Grill&Wine  [0.022152040153741837, 0.01048024371266365, -0...\n",
       "3             Secret Garden  [0.01569896563887596, 0.009590079076588154, -0..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings_sushi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Search function (modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function\n",
    "def ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 1\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"Restaurant\"], relatedness_fn(query_embedding, row[\"Embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sasou'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use ranked by relatedness function\n",
    "strings, relatednesses = ranked_by_relatedness(\"I want a restaurant with a low price range\", df_embeddings_sushi, top_n=1)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Recap\n",
    "\n",
    "The sushi.json file was embedded with an embedding model using the OpenAI API. For each restaurant in the JSON file, one embedding was generated.\n",
    "Queries are then embedded with the same model, and the ranked_by_relatedness function then calculates the relatedness between the query and each \n",
    "embedding from the json file. The top N embeddings are returned.\n",
    "\n",
    "For the sushi or parking use case this is not the right approach.\n",
    "Example: When asking for a budget restaurant, calculating the relatedness using embeddings does not result in giving back the entry with the lowest price range indicator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
